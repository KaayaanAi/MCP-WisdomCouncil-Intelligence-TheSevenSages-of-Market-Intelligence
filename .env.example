# ===============================================
# MCP NextGen Financial Intelligence - Environment Configuration
# ===============================================
# âš ï¸  SECURITY WARNING: NEVER commit real API keys to version control!
# Copy this file to .env and replace placeholders with your actual values
# 
# Required: Only OPENAI_API_KEY is mandatory for basic functionality
# Optional: Other keys enhance features but are not required

# ===============================================
# AI PROVIDER CONFIGURATION
# ===============================================
# Choose your preferred AI provider for cost optimization and reliability
# Providers are tried in fallback order if primary fails

# ðŸŽ¯ AI_PROVIDER: Sets the primary provider (auto-detects if not set)
# Options: openai, anthropic, gemini, local
# Leave empty for automatic detection based on available API keys
AI_PROVIDER=

# ===============================================
# OPENAI CONFIGURATION
# ===============================================
# ðŸ”‘ Get your API key from: https://platform.openai.com/account/api-keys
# ðŸ’° Cost: Moderate (gpt-4o-mini recommended for cost efficiency)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4o-mini

# ===============================================
# ANTHROPIC CLAUDE CONFIGURATION (RECOMMENDED FOR COST)
# ===============================================
# ðŸ”‘ Get your API key from: https://console.anthropic.com/
# ðŸ’° Cost: Very cost-effective with claude-3-haiku (recommended default)
# ðŸš€ Performance: Excellent reasoning and analysis capabilities
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_MODEL=claude-3-haiku-20240307

# Available Anthropic models (in order of cost):
# claude-3-haiku-20240307    - Most cost-effective, fast responses
# claude-3-sonnet-20240229   - Balanced performance and cost
# claude-3-opus-20240229     - Highest performance, most expensive

# ===============================================
# LOCAL MODEL CONFIGURATION (FREE!)
# ===============================================
# ðŸ”‘ No API key needed - runs locally with Ollama
# ðŸ’° Cost: FREE (only local hardware costs)
# ðŸ“‹ Setup: Install Ollama from https://ollama.ai/
# ðŸš€ Run: ollama serve (starts local server on port 11434)
LOCAL_MODEL_URL=http://localhost:11434
LOCAL_MODEL_NAME=llama2

# Popular local models (download with: ollama pull MODEL_NAME):
# llama2           - General purpose, good balance
# codellama        - Code-focused analysis
# mistral          - Efficient, good performance
# llama2:13b       - Larger model, better quality
# codellama:13b    - Larger code model

# ===============================================
# Server Configuration
# ===============================================
# Set to 'true' for HTTP server mode, 'false' for STDIO MCP mode
HTTP_MODE=false
HTTP_PORT=3001
NODE_ENV=development

# ===============================================
# GOOGLE GEMINI CONFIGURATION
# ===============================================
# ðŸ”‘ Get your API key from: https://ai.google.dev/
# ðŸ’° Cost: Free tier available, competitive pricing
# ðŸš€ Performance: Strong reasoning, good for analysis
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-pro

# Available Gemini models:
# gemini-pro       - Main production model
# gemini-1.5-pro   - Latest version with improvements

# ===============================================
# OPTIONAL: Additional AI Providers (for redundancy)
# ===============================================
# These providers offer additional fallback options

# ðŸ”‘ DeepSeek API - Get from: https://platform.deepseek.com/
# ðŸ’° Cost: Very competitive pricing
DEEPSEEK_API_KEY=your_deepseek_api_key_here

# ðŸ”‘ Groq API - Get from: https://console.groq.com/
# ðŸ’° Cost: Fast inference, competitive pricing
GROQ_API_KEY=your_groq_api_key_here

# ðŸ”‘ OpenRouter API - Get from: https://openrouter.ai/
# ðŸ’° Cost: Access to multiple models through one API
OPENROUTER_API_KEY=your_openrouter_api_key_here

# ===============================================
# ADVANCED AI PROVIDER CONFIGURATION
# ===============================================
# ðŸŽ¯ Fine-tune your provider strategy for optimal cost and performance

# PRIMARY_AI_PROVIDER: Manual override (if AI_PROVIDER not set)
PRIMARY_AI_PROVIDER=anthropic

# FALLBACK_AI_PROVIDERS: Comma-separated list of backup providers
# Default order prioritizes cost-effectiveness: anthropic -> local -> gemini -> deepseek
FALLBACK_AI_PROVIDERS=anthropic,local,gemini,deepseek

# ðŸ’¡ COST OPTIMIZATION TIPS:
# 1. Use anthropic with claude-3-haiku for best cost/performance ratio
# 2. Set up local models (Ollama) for unlimited free usage
# 3. Keep multiple API keys for redundancy and rate limit avoidance
# 4. Monitor your usage through provider dashboards

# Database Configuration
MONGODB_URI=mongodb://localhost:27017/financial-intelligence
REDIS_URL=redis://localhost:6379

# News API Configuration
NEWSAPI_KEY=your_newsapi_key_here
GNEWS_API_KEY=your_gnews_api_key_here
CURRENTS_API_KEY=your_currents_api_key_here

# Security Configuration
RATE_LIMIT_WINDOW_MS=900000
RATE_LIMIT_MAX_REQUESTS=100
LOG_LEVEL=info

# TradingView Integration
TRADINGVIEW_WEBHOOK_SECRET=your_webhook_secret_here

# Analysis Configuration
DEFAULT_ANALYSIS_DEPTH=standard
MAX_NEWS_AGE_HOURS=24
CACHE_DURATION_HOURS=12
TRIPLE_VERIFICATION_THRESHOLD=0.7